# Analysis Workflows

This document summarizes typical analysis workflows for post-processing RG pipeline outputs.

## Workflow Steps
1. **Pull data from cluster:**
   - Use `file_management.py` to retrieve job outputs (histograms, stats, configs) to local storage.
2. **Run analysis scripts:**
   - Example: `python -m analysis.critical_exponent --version <version> --mode EXP`
   - Scripts detect config presence and adapt logic automatically.
3. **Review outputs:**
   - Plots and stats are written to `stats/` and `plots/` subfolders under the version directory.
   - Publication-quality plots are generated by `report_plots.py`.

## Example Commands
```bash
python -m analysis.plot_stats --version fp_iqhe_numerical_shaw --steps 9 --start 0 --end 8
python -m analysis.report_plots --version fp_iqhe_numerical_shaw
```

## Notes
- Analysis scripts are intended for local use only; do not run on the cluster.
- Backwards compatibility is maintained for legacy data (no config file), but limitations apply (see DATA_FORMATS.md).
- Assumption: Data layout and naming follow conventions described in repo docs.

See README.md and DATA_FORMATS.md for further details.